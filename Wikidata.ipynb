{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from wikidataintegrator import wdi_core, wdi_login\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "%run 'Shared.ipynb'\n",
    "wdsparql = init_wd_sparql()\n",
    "wbsparql = init_wb_sparql()\n",
    "wb_endpoint, wb_login = init_wb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know the shape of the data we want to retrieve from Wikidata, we will look up a dynamic list of properties that are identifiers that can match entities to other data sets.\n",
    "\n",
    "There are thousands of exteneral identifiers in Wikidata, so we will limit our search tosome that are found on some fairly well knows place items.\n",
    "\n",
    "https://w.wiki/72sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    property_id                       property_label\n",
      "0         P1669  Cultural Objects Names Authority ID\n",
      "1         P3108                              Yelp ID\n",
      "2         P4272                    DPLA subject term\n",
      "3         P4986                 Routard.com place ID\n",
      "4         P9346           France24 topic ID (French)\n",
      "..          ...                                  ...\n",
      "164      P11137                      Reddit topic ID\n",
      "165       P8119                                 HASC\n",
      "166       P7302                      Digital Giza ID\n",
      "167       P8406                  Grove Art Online ID\n",
      "168      P10397                         SBN place ID\n",
      "\n",
      "[169 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set the query\n",
    "query = '''\n",
    "SELECT DISTINCT ?property ?propertyLabel\n",
    "WHERE {\n",
    "  VALUES ?item {\n",
    "    wd:Q243   # Eiffel Tower\n",
    "    wd:Q41225 # Big Ben\n",
    "    wd:Q9188  # Empire State Building\n",
    "    wd:Q37200 # Great Pyramid of Giza\n",
    "    wd:Q934   # North Pole\n",
    "    wd:Q1899  # Kyiv\n",
    "  }\n",
    "  ?item ?p ?statement .\n",
    "  ?property wikibase:claim ?p .\n",
    "  ?property a wikibase:Property ;\n",
    "            wikibase:propertyType wikibase:ExternalId .\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Set the SPARQL query and request JSON response\n",
    "wdsparql.setQuery(query)\n",
    "\n",
    "# Execute the SPARQL query\n",
    "results = wdsparql.query().convert()\n",
    "\n",
    "# Extract the property data from the results\n",
    "properties = []\n",
    "for result in results['results']['bindings']:\n",
    "    prop_id = result['property']['value'].split('/')[-1]\n",
    "    prop_label = result['propertyLabel']['value']\n",
    "    properties.append({'property_id': prop_id, 'property_label': prop_label})\n",
    "\n",
    "# Convert the list of properties to a Pandas DataFrame\n",
    "df_properties = pd.DataFrame(properties)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go ahead and create all of these properties on our Wikibase instance, so that we can use them in the future..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create properties that don't exist locally                                \n",
    "for index, row in df_properties.iterrows():\n",
    "    property_id = row['property_id']\n",
    "    property_label = row['property_label']\n",
    "    map_name = 'wikidata/' + property_id\n",
    "    source_pid = known_lookup(\"source\")\n",
    "    source_id_pid = known_lookup(\"source-id\")\n",
    "\n",
    "    # Check if the property already exists\n",
    "    if known_lookup(map_name) is not None:\n",
    "        print(\"Property already exists: \" + property_label)\n",
    "        continue\n",
    "\n",
    "    # Create the property\n",
    "    s = [\n",
    "        wdi_core.WDString(\"wikidata\", prop_nr=source_pid),\n",
    "        wdi_core.WDString(property_id, prop_nr=source_id_pid)\n",
    "        ]\n",
    "    property = wdi_core.WDItemEngine(mediawiki_api_url=wb_endpoint, data=s)\n",
    "    property.set_label(\"Wikidata: \" + property_label)\n",
    "    property.set_aliases([map_name])\n",
    "\n",
    "    # Write and catch errors, as wikibase.cloud can be a bit slow in allowing us to lookup existing things sometimes\n",
    "    try:\n",
    "        property.write(login=wb_login,entity_type='property', property_datatype='string')\n",
    "        known_add(map_name, property.wd_item_id)\n",
    "    except Exception as e:\n",
    "        if 'label-conflict' in str(e):\n",
    "            known_add(map_name, re.search(r'\\[\\[Property:([^|]+)\\|', str(e)).group(1))\n",
    "            print(\"Property already exists: (caught from error)\")\n",
    "        else:\n",
    "            print(\"Error creating property: \" + str(e))\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below looks for all locations that are 2.3 km away from the Empire State Building.\n",
    "Viewable online at https://w.wiki/72rQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          place  \\\n",
      "0        http://www.wikidata.org/entity/Q389336   \n",
      "1        http://www.wikidata.org/entity/Q431339   \n",
      "2        http://www.wikidata.org/entity/Q692137   \n",
      "3        http://www.wikidata.org/entity/Q939753   \n",
      "4        http://www.wikidata.org/entity/Q964460   \n",
      "...                                         ...   \n",
      "3161  http://www.wikidata.org/entity/Q112957671   \n",
      "3162  http://www.wikidata.org/entity/Q119221764   \n",
      "3163  http://www.wikidata.org/entity/Q119221846   \n",
      "3164  http://www.wikidata.org/entity/Q119221860   \n",
      "3165  http://www.wikidata.org/entity/Q119221894   \n",
      "\n",
      "                               location                              P3417  \\\n",
      "0              Point(-73.9849 40.74558)  American-Academy-of-Dramatic-Arts   \n",
      "1           Point(-73.985972 40.745278)                                NaN   \n",
      "2     Point(-73.974722222 40.736388888)                                NaN   \n",
      "3            Point(-73.984165 40.74329)                                NaN   \n",
      "4           Point(-73.984889 40.745556)                                NaN   \n",
      "...                                 ...                                ...   \n",
      "3161            Point(-73.9854 40.7522)                                NaN   \n",
      "3162              Point(-73.987 40.756)                                NaN   \n",
      "3163              Point(-73.987 40.756)                                NaN   \n",
      "3164        Point(-73.984208 40.754799)                                NaN   \n",
      "3165              Point(-73.987 40.756)                                NaN   \n",
      "\n",
      "                P7859          P2002       P646        P244       P214  \\\n",
      "0     lccn-no97013633  TheAcademyNow  /m/06182p  no97013633  145725284   \n",
      "1                 NaN            NaN  /m/0bf7gr         NaN        NaN   \n",
      "2                 NaN            NaN  /m/02g1n3         NaN        NaN   \n",
      "3                 NaN            NaN  /m/0367t3         NaN        NaN   \n",
      "4                 NaN            NaN  /m/0c4bwr         NaN        NaN   \n",
      "...               ...            ...        ...         ...        ...   \n",
      "3161              NaN            NaN        NaN         NaN        NaN   \n",
      "3162              NaN            NaN        NaN         NaN        NaN   \n",
      "3163              NaN            NaN        NaN         NaN        NaN   \n",
      "3164              NaN            NaN        NaN         NaN        NaN   \n",
      "3165              NaN            NaN        NaN         NaN        NaN   \n",
      "\n",
      "                                    placeLabel  P5383  ... P6404 P10291 P5904  \\\n",
      "0            American Academy of Dramatic Arts    NaN  ...   NaN    NaN   NaN   \n",
      "1     Church of the Transfiguration, Episcopal  33013  ...   NaN    NaN   NaN   \n",
      "2                         Landing at Kip's Bay    NaN  ...   NaN    NaN   NaN   \n",
      "3                                  28th Street    NaN  ...   NaN    NaN   NaN   \n",
      "4                                  Colony Club  79417  ...   NaN    NaN   NaN   \n",
      "...                                        ...    ...  ...   ...    ...   ...   \n",
      "3161                    Colony Arcade Building    NaN  ...   NaN    NaN   NaN   \n",
      "3162    The Commuter's Lament or A Close Shave    NaN  ...   NaN    NaN   NaN   \n",
      "3163                       New York in Transit    NaN  ...   NaN    NaN   NaN   \n",
      "3164            Times Square Under Bryant Park    NaN  ...   NaN    NaN   NaN   \n",
      "3165  The Return of Spring/The Onset of Winter    NaN  ...   NaN    NaN   NaN   \n",
      "\n",
      "     P5247 P4161 P4619 P10832 P6200 P1667 P9545  \n",
      "0      NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "1      NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "2      NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "3      NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "4      NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "...    ...   ...   ...    ...   ...   ...   ...  \n",
      "3161   NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "3162   NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "3163   NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "3164   NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "3165   NaN   NaN   NaN    NaN   NaN   NaN   NaN  \n",
      "\n",
      "[3166 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set the base query template\n",
    "base_query = '''SELECT ?place ?placeLabel ?location {extra_selects}\n",
    "WHERE\n",
    "{{\n",
    "  wd:Q9188 wdt:P625 ?loc .\n",
    "  SERVICE wikibase:around {{\n",
    "      ?place wdt:P625 ?location .\n",
    "      bd:serviceParam wikibase:center ?loc .\n",
    "      bd:serviceParam wikibase:radius \"2.3\" .\n",
    "  }}\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\" . }}\n",
    "  {optional_clauses}\n",
    "}}\n",
    "'''\n",
    "\n",
    "# Get the list of properties from the DataFrame\n",
    "properties = df_properties['property_id'].tolist()\n",
    "\n",
    "# Generate the SELECT clause and OPTIONAL clauses\n",
    "select_clause = ' '.join(['?{}'.format(re.sub(r'\\W+', '', p)) for p in properties])\n",
    "optionals = '\\n'.join(['OPTIONAL {{ ?place wdt:{} ?{} }}.'.format(p, re.sub(r'\\W+', '', p)) for p in properties])\n",
    "\n",
    "# Build the complete query by inserting the clauses into the base template\n",
    "query = base_query.format(extra_selects=select_clause, optional_clauses=optionals)\n",
    "\n",
    "# Execute the SPARQL query\n",
    "wdsparql.setQuery(query)\n",
    "results = wdsparql.query().convert()\n",
    "\n",
    "# Process the query results and convert to DataFrame\n",
    "bindings = results['results']['bindings']\n",
    "data = [{k: v['value'] for k, v in binding.items()} for binding in bindings]\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's slam this data into a Wikibase..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'P2002'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m v:\n\u001b[0;32m---> 32\u001b[0m     item\u001b[39m.\u001b[39mstatements\u001b[39m.\u001b[39mappend(wdi_core\u001b[39m.\u001b[39mWDString(property_map[k], v))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'P2002'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Iterate over the DataFrame rows and create items in Wikibase\n",
    "for index, row in df_results.iterrows():\n",
    "    # Extract the wikidata id from the place that looks like \"http://www.wikidata.org/entity/Q33341\"\n",
    "    wikidata_id = row['place'].split('/')[-1]\n",
    "\n",
    "    # And extract the location from the location that looks like \"Point(40.748433 -73.985656)\"\n",
    "    # TODO actually handle precision..?\n",
    "    lat, long = row['location'].split('(')[1].split(')')[0].split(' ')\n",
    "\n",
    "## ----------------------------\n",
    "## TODO got here, but perhaps we should just import \"Wikidata ID\" property, instead of \"source\" and \"id\"...?\n",
    "## Depends if we want to desing having multiple items per entity into the model or no.. probably not..\n",
    "\n",
    "\n",
    "\n",
    "    # Use the query service to see if the item already exists\n",
    "    query = '''\n",
    "    SELECT ?item WHERE {{\n",
    "        ?item wdt:{} wd:{} .\n",
    "    }}\n",
    "    '''.format(wikidata_map_property, wikidata_id)\n",
    "    wbsparql.setQuery(query)\n",
    "    results = wbsparql.query().convert()\n",
    "    if len(results['results']['bindings']) > 0:\n",
    "        print('Local Item already exists: {}'.format(results['results']['bindings'][0]['item']['value']))\n",
    "        continue\n",
    "\n",
    "    # Create the item\n",
    "    s = [\n",
    "        wdi_core.WDGlobeCoordinate(latitude=lat, longitude=long, precision=0.0001, prop_nr=location_property),\n",
    "        wdi_core.WDString(wikidata_map_property, wikidata_id)\n",
    "    ]\n",
    "    item = wdi_core.WDItemEngine(mediawiki_api_url=wb_endpoint, data=s)\n",
    "    item.set_label(row['placeLabel'])\n",
    "    # Add a statement for every value in the row\n",
    "    for k, v in row.items():\n",
    "        if k in ['place', 'placeLabel', 'location']:\n",
    "            continue\n",
    "        if v:\n",
    "            item.statements.append(wdi_core.WDString(property_map[k], v))\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
