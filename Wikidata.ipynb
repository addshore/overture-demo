{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to get an inital data set out of Wikidata is via the SPARQL endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SPARQLWrapper in /home/adam/.local/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /home/adam/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/adam/.local/lib/python3.10/site-packages (from SPARQLWrapper) (6.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/adam/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/adam/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/adam/.local/lib/python3.10/site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adam/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/lib/python3/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (2.4.7)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/adam/.local/lib/python3.10/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install SPARQLWrapper pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know the shape of the data we want to retrieve from Wikidata, we will look up a dynamic list of properties that are identifiers that can match entities to other data sets.\n",
    "\n",
    "There are thousands of exteneral identifiers in Wikidata, so we will limit our search tosome that are found on some fairly well knows place items.\n",
    "\n",
    "https://w.wiki/72sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    property_id                       property_label\n",
      "0         P1669  Cultural Objects Names Authority ID\n",
      "1         P3108                              Yelp ID\n",
      "2         P4272                    DPLA subject term\n",
      "3         P4986                 Routard.com place ID\n",
      "4         P9346           France24 topic ID (French)\n",
      "..          ...                                  ...\n",
      "164       P9000        World History Encyclopedia ID\n",
      "165       P3836                   Pinterest username\n",
      "166       P5421      Trading Card Database person ID\n",
      "167       P7982            Hrvatska enciklopedija ID\n",
      "168       P7302                      Digital Giza ID\n",
      "\n",
      "[169 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Set up the SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# Set the query\n",
    "query = '''\n",
    "SELECT DISTINCT ?property ?propertyLabel\n",
    "WHERE {\n",
    "  VALUES ?item {\n",
    "    wd:Q243   # Eiffel Tower\n",
    "    wd:Q41225 # Big Ben\n",
    "    wd:Q9188  # Empire State Building\n",
    "    wd:Q37200 # Great Pyramid of Giza\n",
    "    wd:Q934   # North Pole\n",
    "    wd:Q1899  # Kyiv\n",
    "  }\n",
    "  ?item ?p ?statement .\n",
    "  ?property wikibase:claim ?p .\n",
    "  ?property a wikibase:Property ;\n",
    "            wikibase:propertyType wikibase:ExternalId .\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Set the SPARQL query and request JSON response\n",
    "sparql.setMethod(\"POST\")\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "# Execute the SPARQL query\n",
    "results = sparql.query().convert()\n",
    "\n",
    "# Extract the property data from the results\n",
    "properties = []\n",
    "for result in results['results']['bindings']:\n",
    "    prop_id = result['property']['value'].split('/')[-1]\n",
    "    prop_label = result['propertyLabel']['value']\n",
    "    properties.append({'property_id': prop_id, 'property_label': prop_label})\n",
    "\n",
    "# Convert the list of properties to a Pandas DataFrame\n",
    "import pandas as pd\n",
    "df_properties = pd.DataFrame(properties)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below looks for all locations that are 2.3 km away from the Empire State Building.\n",
    "Viewable online at https://w.wiki/72rQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          place  \\\n",
      "0        http://www.wikidata.org/entity/Q502218   \n",
      "1        http://www.wikidata.org/entity/Q502218   \n",
      "2        http://www.wikidata.org/entity/Q502218   \n",
      "3        http://www.wikidata.org/entity/Q502218   \n",
      "4        http://www.wikidata.org/entity/Q652452   \n",
      "...                                         ...   \n",
      "3151  http://www.wikidata.org/entity/Q107015084   \n",
      "3152  http://www.wikidata.org/entity/Q107518923   \n",
      "3153  http://www.wikidata.org/entity/Q107519732   \n",
      "3154  http://www.wikidata.org/entity/Q107519846   \n",
      "3155  http://www.wikidata.org/entity/Q107657642   \n",
      "\n",
      "                               location                              P4272  \\\n",
      "0         Point(-73.98675 40.737694444)  National Academy of Design (U.S.)   \n",
      "1         Point(-73.98675 40.737694444)  National Academy of Design (U.S.)   \n",
      "2         Point(-73.98675 40.737694444)  National Academy of Design (U.S.)   \n",
      "3         Point(-73.98675 40.737694444)  National Academy of Design (U.S.)   \n",
      "4          Point(-73.9875 40.741111111)                                NaN   \n",
      "...                                 ...                                ...   \n",
      "3151   Point(-73.970348973 40.75097977)                                NaN   \n",
      "3152         Point(-73.971818 40.74793)                                NaN   \n",
      "3153        Point(-73.972543 40.750364)                                NaN   \n",
      "3154         Point(-73.971818 40.74793)                                NaN   \n",
      "3155  Point(-73.971666666 40.749444444)                                NaN   \n",
      "\n",
      "                                     P9885  \\\n",
      "0     36db7948-99f2-a548-826c-eef0bec11e71   \n",
      "1     36db7948-99f2-a548-826c-eef0bec11e71   \n",
      "2     36db7948-99f2-a548-826c-eef0bec11e71   \n",
      "3     36db7948-99f2-a548-826c-eef0bec11e71   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "3151                                   NaN   \n",
      "3152                                   NaN   \n",
      "3153                                   NaN   \n",
      "3154                                   NaN   \n",
      "3155                                   NaN   \n",
      "\n",
      "                                                P3417           P7859  \\\n",
      "0     National-Academy-Museum-and-School-of-Fine-Arts  lccn-n50074752   \n",
      "1     National-Academy-Museum-and-School-of-Fine-Arts  lccn-n50074752   \n",
      "2     National-Academy-Museum-and-School-of-Fine-Arts  lccn-n50074752   \n",
      "3     National-Academy-Museum-and-School-of-Fine-Arts  lccn-n50074752   \n",
      "4                                                 NaN  lccn-n50081001   \n",
      "...                                               ...             ...   \n",
      "3151                                              NaN             NaN   \n",
      "3152                                              NaN             NaN   \n",
      "3153                                              NaN             NaN   \n",
      "3154                                              NaN             NaN   \n",
      "3155                                              NaN             NaN   \n",
      "\n",
      "                               P4702        P2002                 P3749  \\\n",
      "0     national-academy-museum-school  NatlAcademy  14955316417986489272   \n",
      "1     national-academy-museum-school  NatlAcademy  14955316417986489272   \n",
      "2     national-academy-museum-school  NatlAcademy  14955316417986489272   \n",
      "3     national-academy-museum-school  NatlAcademy  14955316417986489272   \n",
      "4                                NaN          NaN                   NaN   \n",
      "...                              ...          ...                   ...   \n",
      "3151                             NaN          NaN                   NaN   \n",
      "3152                             NaN          NaN                   NaN   \n",
      "3153                             NaN          NaN                   NaN   \n",
      "3154                             NaN          NaN                   NaN   \n",
      "3155                             NaN          NaN                   NaN   \n",
      "\n",
      "            P2013  ... P9545 P8569 P6404 P10291 P4619 P5904 P5247 P10832  \\\n",
      "0     natlacademy  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "1     natlacademy  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "2     natlacademy  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "3     natlacademy  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "4             NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "...           ...  ...   ...   ...   ...    ...   ...   ...   ...    ...   \n",
      "3151          NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "3152          NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "3153          NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "3154          NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "3155          NaN  ...   NaN   NaN   NaN    NaN   NaN   NaN   NaN    NaN   \n",
      "\n",
      "     P6385 P4161  \n",
      "0      NaN   NaN  \n",
      "1      NaN   NaN  \n",
      "2      NaN   NaN  \n",
      "3      NaN   NaN  \n",
      "4      NaN   NaN  \n",
      "...    ...   ...  \n",
      "3151   NaN   NaN  \n",
      "3152   NaN   NaN  \n",
      "3153   NaN   NaN  \n",
      "3154   NaN   NaN  \n",
      "3155   NaN   NaN  \n",
      "\n",
      "[3156 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import re\n",
    "\n",
    "# Set up the SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# Set the base query template\n",
    "base_query = '''SELECT ?place ?placeLabel ?location {extra_selects}\n",
    "WHERE\n",
    "{{\n",
    "  wd:Q9188 wdt:P625 ?loc .\n",
    "  SERVICE wikibase:around {{\n",
    "      ?place wdt:P625 ?location .\n",
    "      bd:serviceParam wikibase:center ?loc .\n",
    "      bd:serviceParam wikibase:radius \"2.3\" .\n",
    "  }}\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\" . }}\n",
    "  {optional_clauses}\n",
    "}}\n",
    "'''\n",
    "\n",
    "# Get the list of properties from the DataFrame\n",
    "properties = df_properties['property_id'].tolist()\n",
    "\n",
    "# Generate the SELECT clause and OPTIONAL clauses\n",
    "select_clause = ' '.join(['?{}'.format(re.sub(r'\\W+', '', p)) for p in properties])\n",
    "optionals = '\\n'.join(['OPTIONAL {{ ?place wdt:{} ?{} }}.'.format(p, re.sub(r'\\W+', '', p)) for p in properties])\n",
    "\n",
    "# Build the complete query by inserting the clauses into the base template\n",
    "query = base_query.format(extra_selects=select_clause, optional_clauses=optionals)\n",
    "\n",
    "# Set the SPARQL query and request JSON response\n",
    "sparql.setMethod(\"POST\")\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "# Execute the SPARQL query\n",
    "results = sparql.query().convert()\n",
    "\n",
    "# Process the query results and convert to DataFrame\n",
    "bindings = results['results']['bindings']\n",
    "data = [{k: v['value'] for k, v in binding.items()} for binding in bindings]\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's slam this data into a Wikibase...\n",
    "For that we will use wikidataintegrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wikidataintegrator in /home/adam/.local/lib/python3.10/site-packages (0.9.30)\n",
      "Requirement already satisfied: tqdm in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (4.65.0)\n",
      "Requirement already satisfied: backoff in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (2.2.1)\n",
      "Requirement already satisfied: oauthlib in /usr/lib/python3/dist-packages (from wikidataintegrator) (3.2.0)\n",
      "Requirement already satisfied: jsonasobj in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (1.3.1)\n",
      "Requirement already satisfied: pyshex in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (0.8.1)\n",
      "Requirement already satisfied: simplejson in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (3.19.1)\n",
      "Requirement already satisfied: mwoauth in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (0.3.8)\n",
      "Requirement already satisfied: python-dateutil in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (2.8.2)\n",
      "Requirement already satisfied: shexer in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (2.2.0)\n",
      "Requirement already satisfied: requests in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (2.31.0)\n",
      "Requirement already satisfied: pandas in /home/adam/.local/lib/python3.10/site-packages (from wikidataintegrator) (2.0.3)\n",
      "Requirement already satisfied: requests-oauthlib in /home/adam/.local/lib/python3.10/site-packages (from mwoauth->wikidataintegrator) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from mwoauth->wikidataintegrator) (1.16.0)\n",
      "Requirement already satisfied: PyJWT>=1.0.1 in /usr/lib/python3/dist-packages (from mwoauth->wikidataintegrator) (2.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/adam/.local/lib/python3.10/site-packages (from pandas->wikidataintegrator) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adam/.local/lib/python3.10/site-packages (from pandas->wikidataintegrator) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/adam/.local/lib/python3.10/site-packages (from pandas->wikidataintegrator) (1.25.1)\n",
      "Requirement already satisfied: sparqlwrapper>=1.8.5 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (2.0.0)\n",
      "Requirement already satisfied: pyshexc==0.9.1 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (0.9.1)\n",
      "Requirement already satisfied: cfgraph>=0.2.1 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (0.2.1)\n",
      "Requirement already satisfied: rdflib-shim in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (1.0.3)\n",
      "Requirement already satisfied: sparqlslurper>=0.5.1 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (0.5.1)\n",
      "Requirement already satisfied: urllib3 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (2.0.3)\n",
      "Requirement already satisfied: chardet in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (5.1.0)\n",
      "Requirement already satisfied: shexjsg>=0.8.2 in /home/adam/.local/lib/python3.10/site-packages (from pyshex->wikidataintegrator) (0.8.2)\n",
      "Requirement already satisfied: pyjsg>=0.11.10 in /home/adam/.local/lib/python3.10/site-packages (from pyshexc==0.9.1->pyshex->wikidataintegrator) (0.11.10)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.9.3 in /home/adam/.local/lib/python3.10/site-packages (from pyshexc==0.9.1->pyshex->wikidataintegrator) (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adam/.local/lib/python3.10/site-packages (from requests->wikidataintegrator) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adam/.local/lib/python3.10/site-packages (from requests->wikidataintegrator) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adam/.local/lib/python3.10/site-packages (from requests->wikidataintegrator) (2023.5.7)\n",
      "Requirement already satisfied: Flask-Cors in /home/adam/.local/lib/python3.10/site-packages (from shexer->wikidataintegrator) (4.0.0)\n",
      "Requirement already satisfied: rdflib-jsonld in /home/adam/.local/lib/python3.10/site-packages (from shexer->wikidataintegrator) (0.6.1)\n",
      "Requirement already satisfied: rdflib in /home/adam/.local/lib/python3.10/site-packages (from shexer->wikidataintegrator) (6.3.2)\n",
      "Requirement already satisfied: wlighter in /home/adam/.local/lib/python3.10/site-packages (from shexer->wikidataintegrator) (1.0.1)\n",
      "Requirement already satisfied: Flask in /home/adam/.local/lib/python3.10/site-packages (from shexer->wikidataintegrator) (2.3.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/lib/python3/dist-packages (from rdflib->shexer->wikidataintegrator) (2.4.7)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/adam/.local/lib/python3.10/site-packages (from rdflib->shexer->wikidataintegrator) (0.6.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/adam/.local/lib/python3.10/site-packages (from Flask->shexer->wikidataintegrator) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.3.3 in /home/adam/.local/lib/python3.10/site-packages (from Flask->shexer->wikidataintegrator) (2.3.6)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/adam/.local/lib/python3.10/site-packages (from Flask->shexer->wikidataintegrator) (8.1.5)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/adam/.local/lib/python3.10/site-packages (from Flask->shexer->wikidataintegrator) (3.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/adam/.local/lib/python3.10/site-packages (from Flask->shexer->wikidataintegrator) (1.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adam/.local/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask->shexer->wikidataintegrator) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikidataintegrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while writing to Wikidata\n",
      "Property already exists: DPLA subject term is P41\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Bing entity ID is P42\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Quora topic ID is P43\n",
      "Error while writing to Wikidata\n",
      "Property already exists: WorldCat Identities ID (superseded) is P30\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Google Arts & Culture partner ID is P49\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Twitter username is P50\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Google Maps Customer ID is P51\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Facebook ID is P40\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Instagram username is P53\n",
      "Error while writing to Wikidata\n",
      "Property already exists: National Library of Israel J9U ID is P54\n",
      "Error while writing to Wikidata\n",
      "Property already exists: TripAdvisor ID is P55\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Open Library subject ID is P56\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Wolfram Language entity code is P57\n",
      "Error while writing to Wikidata\n",
      "Property already exists: National Library of Latvia ID is P58\n",
      "Error while writing to Wikidata\n",
      "Property already exists: NL CR AUT ID is P59\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Biblioteca Nacional de España ID is P60\n",
      "Error while writing to Wikidata\n",
      "Property already exists: GeoNames ID is P36\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Freebase ID is P32\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Encyclopedia of China (Third Edition) ID is P63\n",
      "Error while writing to Wikidata\n",
      "Property already exists: IdRef ID is P64\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Library of Congress authority ID is P33\n",
      "Error while writing to Wikidata\n",
      "Property already exists: GNIS ID is P66\n",
      "Error while writing to Wikidata\n",
      "Property already exists: NORAF ID is P67\n",
      "Error while writing to Wikidata\n",
      "Property already exists: GND ID is P68\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Bibliothèque nationale de France ID is P69\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Encyclopædia Britannica Online ID is P70\n",
      "Error while writing to Wikidata\n",
      "Property already exists: VIAF ID is P35\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Grove Art Online ID is P72\n",
      "Error while writing to Wikidata\n",
      "Property already exists: archINFORM project ID is P31\n",
      "Error while writing to Wikidata\n",
      "Property already exists: SkyscraperPage building ID is P74\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Emporis building ID is P75\n",
      "Error while writing to Wikidata\n",
      "Property already exists: NRHP reference number is P34\n",
      "Error while writing to Wikidata\n",
      "Property already exists: CTBUH Skyscraper Center building ID is P77\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Structurae structure ID is P78\n",
      "Error while writing to Wikidata\n",
      "Property already exists: New York City Landmarks Preservation Commission ID is P79\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Den Store Danske ID is P80\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Encyclopædia Universalis ID is P81\n",
      "Error while writing to Wikidata\n",
      "Property already exists: NE.se ID is P82\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Store norske leksikon ID is P83\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Brockhaus Enzyklopädie online ID is P84\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Gran Enciclopèdia Catalana ID is P85\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Treccani ID is P86\n",
      "Error while writing to Wikidata\n",
      "Property already exists: OpenAlex ID is P87\n",
      "Error while writing to Wikidata\n",
      "Property already exists: subreddit is P88\n",
      "Error while writing to Wikidata\n",
      "Property already exists: FAST ID is P89\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Who's on First ID is P90\n",
      "Error while writing to Wikidata\n",
      "Property already exists: OpenStreetMap node ID is P37\n",
      "Error while writing to Wikidata\n",
      "Property already exists: MusicBrainz place ID is P92\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Playbill venue ID is P93\n",
      "Error while writing to Wikidata\n",
      "Property already exists: YouTube channel ID is P39\n",
      "Error while writing to Wikidata\n",
      "Property already exists: National Library of Israel ID (old) is P95\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Cultural Objects Names Authority ID is P96\n",
      "Error while writing to Wikidata\n",
      "Property already exists: French Vikidia ID is P97\n",
      "Error while writing to Wikidata\n",
      "Property already exists: U.S. National Archives Identifier is P98\n",
      "Error while writing to Wikidata\n",
      "Property already exists: iNaturalist place ID is P99\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Foursquare City Guide venue ID is P100\n",
      "Error while writing to Wikidata\n",
      "Property already exists: MusicBrainz area ID is P101\n",
      "Error while writing to Wikidata\n",
      "Property already exists: archINFORM location ID is P102\n",
      "Error while writing to Wikidata\n",
      "Property already exists: UK Parliament thesaurus ID is P103\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Pinterest username is P104\n",
      "Error while writing to Wikidata\n",
      "Property already exists: OpenStreetMap relation ID is P105\n",
      "Error while writing to Wikidata\n",
      "Property already exists: BabelNet ID is P106\n",
      "Error while writing to Wikidata\n",
      "Property already exists: setlist.fm venue ID is P107\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Songkick venue ID is P108\n",
      "Error while writing to Wikidata\n",
      "Property already exists: SAPA ID is P109\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Yelp ID is P38\n",
      "Error while writing to Wikidata\n",
      "Property already exists: OpenStreetMap way ID is P111\n",
      "Error while writing to Wikidata\n",
      "Property already exists: BBC Things ID is P112\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Google+ ID is P113\n",
      "Error while writing to Wikidata\n",
      "Property already exists: KBpedia ID is P114\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Interlingual Index ID is P115\n",
      "Error while writing to Wikidata\n",
      "Property already exists: WordNet 3.1 Synset ID is P116\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Instagram location ID is P117\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Online PWN Encyclopedia ID is P118\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Great Russian Encyclopedia Online ID (old version) is P119\n",
      "Error while writing to Wikidata\n",
      "Property already exists: GitHub topic is P120\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Golden ID is P121\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Google News topics ID is P122\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Fandom article ID is P123\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Mapy.cz ID is P124\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Jewish Encyclopedia ID (Russian) is P125\n",
      "Error while writing to Wikidata\n",
      "Property already exists: FactGrid item ID is P126\n",
      "Error while writing to Wikidata\n",
      "Property already exists: ScienceDirect topic ID is P127\n",
      "Error while writing to Wikidata\n",
      "Property already exists: BBC News topic ID is P128\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Getty Thesaurus of Geographic Names ID is P129\n",
      "Error while writing to Wikidata\n",
      "Property already exists: National Trust for Historic Preservation ID is P130\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Proleksis enciklopedija ID is P131\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Larousse ID is P132\n",
      "Error while writing to Wikidata\n",
      "Property already exists: De Agostini ID is P133\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Comic Vine ID is P134\n",
      "Error while writing to Wikidata\n",
      "Property already exists: NDL Authority ID is P135\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Hrvatska enciklopedija ID is P136\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Encyclopedia of China (Second Edition) ID is P137\n",
      "Error while writing to Wikidata\n",
      "Property already exists: YIVO Encyclopedia of Jews in Eastern Europe ID is P138\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Treccani's Dizionario di Storia ID is P139\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Wikisimpsons ID is P140\n",
      "Error while writing to Wikidata\n",
      "Property already exists: National Library of Brazil ID is P141\n",
      "Error while writing to Wikidata\n",
      "Property already exists: ASCE Historical Civil Engineering Landmark ID is P142\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Giant Bomb ID is P143\n",
      "Error while writing to Wikidata\n",
      "Property already exists: WorldCat Entities ID is P144\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Krugosvet article is P145\n",
      "Error while writing to Wikidata\n",
      "Property already exists: Michelin Voyages ID is P146\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m v:\n\u001b[0;32m---> 94\u001b[0m     item\u001b[39m.\u001b[39mstatements\u001b[39m.\u001b[39mappend(wdi_core\u001b[39m.\u001b[39;49mWDString(property_map[k], v))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wikidataintegrator/wdi_core.py:2312\u001b[0m, in \u001b[0;36mWDString.__init__\u001b[0;34m(self, value, prop_nr, is_reference, is_qualifier, snak_type, references, qualifiers, rank, check_qualifier_equality)\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, value, prop_nr, is_reference\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, is_qualifier\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, snak_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, references\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2290\u001b[0m              qualifiers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, rank\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m'\u001b[39m, check_qualifier_equality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   2291\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2292\u001b[0m \u001b[39m    Constructor, calls the superclass WDBaseDataType\u001b[39;00m\n\u001b[1;32m   2293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[39m    :type rank: str\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2312\u001b[0m     \u001b[39msuper\u001b[39;49m(WDString, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(value\u001b[39m=\u001b[39;49mvalue, snak_type\u001b[39m=\u001b[39;49msnak_type, data_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDTYPE,\n\u001b[1;32m   2313\u001b[0m                                    is_reference\u001b[39m=\u001b[39;49mis_reference, is_qualifier\u001b[39m=\u001b[39;49mis_qualifier, references\u001b[39m=\u001b[39;49mreferences,\n\u001b[1;32m   2314\u001b[0m                                    qualifiers\u001b[39m=\u001b[39;49mqualifiers, rank\u001b[39m=\u001b[39;49mrank, prop_nr\u001b[39m=\u001b[39;49mprop_nr,\n\u001b[1;32m   2315\u001b[0m                                    check_qualifier_equality\u001b[39m=\u001b[39;49mcheck_qualifier_equality)\n\u001b[1;32m   2317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_value(value\u001b[39m=\u001b[39mvalue)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wikidataintegrator/wdi_core.py:1996\u001b[0m, in \u001b[0;36mWDBaseDataType.__init__\u001b[0;34m(self, value, snak_type, data_type, is_reference, is_qualifier, references, qualifiers, rank, prop_nr, check_qualifier_equality)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(prop_nr) \u001b[39mis\u001b[39;00m \u001b[39mint\u001b[39m:\n\u001b[1;32m   1995\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprop_nr \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(prop_nr)\n\u001b[0;32m-> 1996\u001b[0m \u001b[39melif\u001b[39;00m prop_nr\u001b[39m.\u001b[39;49mstartswith(\u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1997\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprop_nr \u001b[39m=\u001b[39m prop_nr\n\u001b[1;32m   1998\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wikidataintegrator import wdi_core, wdi_login\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Set up the SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# Auth with Wikibase\n",
    "with open('./.secret.json') as f:\n",
    "    data = json.load(f)\n",
    "    wb_username = data['demo_user']\n",
    "    wb_password = data['demo_password']\n",
    "wb_endpoint = 'https://overture-demo.wikibase.cloud/w/api.php'\n",
    "wb_login = wdi_login.WDLogin(user=wb_username, pwd=wb_password, mediawiki_api_url=wb_endpoint)\n",
    "\n",
    "# Load the base property map\n",
    "with open('./property_map.json') as f:\n",
    "    property_map = json.load(f)\n",
    "wikidata_map_property = property_map['wikidata']\n",
    "location_property = property_map['location']\n",
    "\n",
    "# Iterate through the columns and create any properties that are missing\n",
    "for col in df_results.columns:\n",
    "    if col in ['place', 'placeLabel', 'location']:\n",
    "        continue\n",
    "    # Check using SPAQRL if the property already exists with the matching statement\n",
    "    query = '''\n",
    "    SELECT ?property WHERE {{\n",
    "        ?property wdt:{} wd:{} .\n",
    "    }}\n",
    "    '''.format(wikidata_map_property, col)\n",
    "    sparql.setMethod(\"POST\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if len(results['results']['bindings']) > 0:\n",
    "        print('Property already exists: {}'.format(results['results']['bindings'][0]['property']['value']))\n",
    "        continue\n",
    "\n",
    "    # Get the label from df_properties\n",
    "    label = df_properties[df_properties['property_id'] == col]['property_label'].values[0]\n",
    "\n",
    "    # Create the property\n",
    "    property = wdi_core.WDItemEngine(mediawiki_api_url=wb_endpoint)\n",
    "    property.set_label(label)\n",
    "    property.set_aliases([\"Wikidata:\" + col])\n",
    "    property.statements.append(wdi_core.WDString(col, prop_nr=wikidata_map_property))\n",
    "    # Write and catch errors, as wikibase.cloud can be a bit slow in allowing us to lookup existing things sometimes\n",
    "    try:\n",
    "        property.write(login=wb_login,entity_type='property', property_datatype='external-id')\n",
    "        property_map[col] = property.wd_item_id\n",
    "    except Exception as e:\n",
    "        if 'label-conflict' in str(e):\n",
    "            # Add it to the map\n",
    "            property_map[col] = re.search(r'\\[\\[Property:([^|]+)\\|', str(e)).group(1)\n",
    "            print(\"Property already exists: \" + label + \" is \" + property_map[col])\n",
    "        else:\n",
    "            print(\"Error creating property: \" + str(e))\n",
    "            exit()\n",
    "\n",
    "# Iterate over the DataFrame rows and create items in Wikibase\n",
    "for index, row in df_results.iterrows():\n",
    "    # Extract the wikidata id from the place that looks like \"http://www.wikidata.org/entity/Q33341\"\n",
    "    wikidata_id = row['place'].split('/')[-1]\n",
    "\n",
    "    # And extract the location from the location that looks like \"Point(40.748433 -73.985656)\"\n",
    "    lat, long = row['location'].split('(')[1].split(')')[0].split(' ')\n",
    "    # TODO actually handle precision..?\n",
    "\n",
    "    # Use the query service to see if the item already exists\n",
    "    query = '''\n",
    "    SELECT ?item WHERE {{\n",
    "        ?item wdt:{} wd:{} .\n",
    "    }}\n",
    "    '''.format(wikidata_map_property, wikidata_id)\n",
    "    sparql.setMethod(\"POST\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if len(results['results']['bindings']) > 0:\n",
    "        print('Local Item already exists: {}'.format(results['results']['bindings'][0]['item']['value']))\n",
    "        continue\n",
    "\n",
    "    # Create the item\n",
    "    item = wdi_core.WDItemEngine(mediawiki_api_url=wb_endpoint)\n",
    "    item.set_label(row['placeLabel'])\n",
    "    item.statements.append(wdi_core.WDGlobeCoordinate(latitude=lat, longitude=long, precision=0.0001, prop_nr=location_property))\n",
    "    item.statements.append(wdi_core.WDString(wikidata_map_property, wikidata_id))\n",
    "    # Add a statement for every value in the row\n",
    "    for k, v in row.items():\n",
    "        if k in ['place', 'placeLabel', 'location']:\n",
    "            continue\n",
    "        if v:\n",
    "            item.statements.append(wdi_core.WDString(property_map[k], v))\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
